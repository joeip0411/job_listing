name: CI

on: [pull_request, workflow_dispatch, push]

env:
  AIRFLOW_BASE_URL: "http://localhost:8080"
  AWS_DEFAULT_REGION: "ap-southeast-2"
  AWS_REGION: "ap-southeast-2"
  ENABLE_REMOTE_LOGGING: "False"
  ENV: "dev"
  POSTGRES_DB: "airflow"
  POSTGRES_HOST: "postgres"
  POSTGRES_PASSWORD: "airflow"
  POSTGRES_PORT: "5432"
  POSTGRES_USER: "airflow"
  GLUE_CATALOG: "glue"
  GLUE_DATABASE: "job"
  STAGE: "dev"       

jobs:
  build_test:
    environment: dev
    name: Build Image
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up .env file
        run: |
          touch airflow/.env
          echo  AIRFLOW_BASE_URL=${{ env.AIRFLOW_BASE_URL }} >> airflow/.env
          echo  AWS_DEFAULT_REGION=${{ env.AWS_DEFAULT_REGION }} >> airflow/.env
          echo  AWS_REGION=${{ env.AWS_REGION }} >> airflow/.env
          echo  ENABLE_REMOTE_LOGGING=${{ env.ENABLE_REMOTE_LOGGING }} >> airflow/.env
          echo  AWS_REGION=${{ env.AWS_REGION }} >> airflow/.env
          echo  ENV=${{ env.ENV }} >> airflow/.env
          echo  POSTGRES_DB=${{ env.POSTGRES_DB }} >> airflow/.env
          echo  POSTGRES_HOST=${{ env.POSTGRES_HOST }} >> airflow/.env
          echo  POSTGRES_PORT=${{ env.POSTGRES_PORT }} >> airflow/.env
          echo  POSTGRES_USER=${{ env.POSTGRES_USER }} >> airflow/.env
          echo  GLUE_CATALOG=${{ env.GLUE_CATALOG }} >> airflow/.env
          echo  GLUE_DATABASE=${{ env.GLUE_DATABASE }} >> airflow/.env
          echo  STAGE=${{ env.STAGE }} >> airflow/.env
          echo  AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} >> airflow/.env
          echo  AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} >> airflow/.env
          echo  FERNET_KEY=${{ secrets.FERNET_KEY }} >> airflow/.env
          echo  GLUE_DATABASE_STORAGE_LOCATION=${{ secrets.GLUE_DATABASE_STORAGE_LOCATION }} >> airflow/.env
          cat airflow/.env

      - name: Cache image layers
        uses: actions/cache@v4
        with:
          path: /var/lib/docker
          key: docker-${{ hashFiles('**/Dockerfile') }}-${{ hashFiles('**/*.py') }}-${{ hashFiles('**/*.sql') }}

      - name: Build image and start airflow containers
        run: |
          docker-compose -f "airflow/docker-compose.yml" up --build -d

      - name: Wait for airflow webserver to be healthy
        run: |
          HEALTH=""
          while [ "$HEALTH" != "healthy" ]; do
            HEALTH=$(docker inspect --format='{{.State.Health.Status}}' airflow_webserver_1)
            if [ "$HEALTH" != "healthy" ]; then\
              echo "Waiting for airflow webserver to become healthy..."
              sleep 5
            fi
          done

      - name: Run DAG validation and definition tests
        run: |
          docker exec airflow_webserver_1 python3 -m pytest -vv tests/ 

      - name: Stop airflow containers
        run: |
          docker-compose -f "airflow/docker-compose.yml" down